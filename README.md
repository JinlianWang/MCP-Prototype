# ðŸ§  Hello World MCP Agent (Node.js)

This project demonstrates a minimal, fully MCP-compliant agent setup using Node.js, OpenAI GPT-4, and a tool server. The agent can dynamically discover tools, route prompts to the correct tool(s), and orchestrate multiple tool calls in sequence.

## ðŸ“ Project Structure

```
.
â”œâ”€â”€ client/             # LLM client agent
â”‚   â”œâ”€â”€ llm_client.js
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ server/             # MCP server exposing tools
â”‚   â”œâ”€â”€ server.js
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

---

## ðŸš€ Quick Start

### 1. ðŸ“¦ Install Dependencies

In each folder (`client/` and `server/`), run:

```bash
npm install
```

---

### 2. ðŸ” Setup OpenAI API Key (Client Only)

In `client/`, create a `.env` file:

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

You can create an API key at [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys).

---

### 3. ðŸ–¥ï¸ Start the MCP Server

In `server/`:

```bash
node server.js
```

This starts the MCP tool server on `http://localhost:3000`, with:

- `GET /tools` â€” tool discovery endpoint
- `POST /tools/say_hello` â€” returns a greeting
- `POST /tools/get_time` â€” returns current server time and timezone

---

### 4. ðŸ¤– Run the LLM Agent Client

In a second terminal, from `client/`:

```bash
node llm_client.js
```

This script:
- Loads tools from the MCP server
- Sends a prompt to GPT-4
- Lets the LLM decide which tools to call
- Routes tool calls to the server
- Sends tool outputs back to GPT for final summarization

---

## ðŸ§ª Example Prompt

```txt
Say hello to Sunny and tell me the current time.
```

Expected output:

```
ðŸ”§ Tool calls: [ 'say_hello', 'get_time' ]
ðŸ› ï¸ Called say_hello({"name":"Sunny"}) â†’ { message: 'Hello, Sunny!' }
ðŸ› ï¸ Called get_time({}) â†’ { time: '...', timezone: '...' }

ðŸ’¬ Final GPT Reply:
Hello, Sunny! The current time is 12:34 PM in America/New_York.
```

---

## ðŸ§  Tools Defined in This MCP Server

| Tool        | Description                             | Endpoint                |
|-------------|-----------------------------------------|-------------------------|
| `say_hello` | Returns a greeting for a given name     | `POST /tools/say_hello` |
| `get_time`  | Returns current server time + timezone  | `POST /tools/get_time`  |

All tools are returned via `GET /tools` using OpenAI-compatible schema.

---

## ðŸ› ï¸ Future Improvements (Optional Ideas)

- Format timestamps into friendly local time
- Add more tools like `fetch_url`, `summarize`, etc.
- Store conversations in a database

## ðŸŒ Web UI Agent

This is a browser-based interface to interact with the MCP agent using plain HTML, JavaScript, and a Node.js backend.

### ðŸ“ Folder Structure

```
web-ui/
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html       # Minimal frontend
â”‚   â””â”€â”€ style.css        # Optional basic styling
â”œâ”€â”€ server/
â”‚   â””â”€â”€ api.js           # Node.js backend (CommonJS-style)
â”œâ”€â”€ .env                 # OpenAI API key
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

### ðŸš€ Setup & Run

1. Navigate into `web-ui/`:

```bash
cd web-ui
```

2. Install dependencies:

```bash
npm install
```

3. Add your OpenAI key to `.env`:

```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

4. Start the server:

```bash
node server/api.js
```

5. Open your browser and go to:

```
http://localhost:4000
```

### ðŸ§ª How It Works

- Enter a prompt like:
  > Say hello to Sunny and tell me the current time.

- The backend will:
  - Load tools from the MCP server
  - Let the LLM decide which to call
  - Call tools as needed
  - Return the GPT-synthesized reply

---

## ðŸ“œ License

MIT License â€” use freely, modify responsibly.
